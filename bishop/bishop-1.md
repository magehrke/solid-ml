# Bishop Chapter 1
Author: maxalex

## Introduction
#### Pattern Recognition
#### Machine Learning
#### Training Set
#### Target Vector
#### Training/Learning Phase
#### Test Set
#### Generalization
#### Preprocess / Feature Extraction
#### Supervised Learning
#### Classification
#### Regression
#### Unsupervised Learning
#### Clustering
#### Density Estimation
#### Visualization
#### Reinforcement Learning
#### Credit Assignment Problem
#### Exploration
#### Exploitation
#### Probability Theory
#### Decision Theory
#### Information Theory

## Polynomial Curve Fitting
#### Polynomial Function
#### Linear Models
#### Error Function
#### Sum-of-Squares Error Function
#### Model Comparison / Model Selection
#### Over-Fitting
#### Maximum Likelihood
#### Bayesian Approach
#### Effective Number of Parameters
#### Regularization
#### Ridge Regression
#### Weight Decay
#### Validation Set / Hold-Out Set

## Probability Theory
#### Sum Rule
#### Marginal Probability
#### Product Rule
#### Joint Probability
#### Conditional Probability
#### Random Variable
#### Symmetry Property
#### Bayes' Theorem
#### Prior Probability
#### Posterior Probability
#### Independence

### Probability Densities
#### Probability Density over x
#### Integrals
#### Cumulative Distribution Function
#### Probability Mass Function
#### Densities and Continuous Variables


### Expectations \& Covariances
#### Expectation
#### Conditional Expectation
#### Variance
#### Variance of the variable x
#### Covariance

### Bayesian Probablities
#### Classical / Frequentist interpretation of probablity
#### Bayesian View
#### Bayes' Theorem
#### Likelihood Function
#### Maximum Likelihood
#### Error Function
#### Bootstrap
#### Noninformative Prior

### The Guassian Distribution
#### Guassian / Normal Distribution
#### Mean, Variance, Standard Deviation, Precision
#### Moment
#### Second Order Moment
#### Variance
#### Independent \& Identically distributed
#### Log Likelihood
#### Sample Mean
#### Sample Variance
#### Bias

### Curve fitting re-visited
#### Gaussian Noise Distribution
#### Sum of Squares Error Function
#### Predictive Distribution
#### Hyperparameters
#### Maximum Posterior
#### Guassian Prior

### Bayesian Curve Fitting
#### Bayesian Treatment
#### Point Estimate
#### Full Bayesian

## Model Selection
#### Validation Set
#### Test Set
#### Cross-Validation
#### Akaike Information Criterion
#### Bayesian Information Criterion

## The Curse of Dimensionality
#### Curse of Dimensionality
#### Cartesian vs. Polar Coordinates
#### Directional Variables
#### Reasons for effective techniques in high dimensional data
#### Manifold

## Decision Theory
#### Inference
#### Subject of Decision Theory
#### Decison Step
#### Extract any quantities in Bayes Theorem

### Minimizing the missclassification rate
#### Decision Regions
#### Decision Boundaries or Surfaces
#### Mistake Probability
#### Correct Probability
#### Decision Rule

### Minimizing the expected loss
#### Loss, Cost and Utility Function
#### Loss Matrix
#### Expected Loss
#### Decision Rule

### The reject option
#### Reject Option
#### Rejection Criterion

### Inference and decision
#### Inference Stage
#### Decision Stage
#### Generative Models
#### Discriminative Models
#### Discriminant Function
#### Simple way for Prior Calculation
#### Outlier Detection
#### Advantages of Posterior Probability Estimation (4)
#### Conditional Independence
#### Naive Bayes Model

### Loss functions for regression
#### Loss function in regression
#### Regression Function
#### Irreducible Minimum Value of Loss Function
#### Three distinct Approaches
#### Poor Results of Squared Loss
#### Minkowski Loss

## Information Theory
#### Idea of Information Theory
#### Monotonic Function
#### Definition of Information
#### Entropy
#### Noiseless Coding Theorem
#### nats
#### Multiplicity
#### Microstate, Macrostate, weight of Macrostate
#### H[p]
#### Lagrange Multiplier
#### Maximum Entropy Configuration
#### Jensen's inequality
#### Mean Value Theorem
#### Differential Entropy
#### Maximum of Differential Entropy
#### Calculus of Variation
#### Negativity of Differential Entropy
#### Conditional Entropy
#### Relation between differential \& conditional entropy

### Relative entropy \& mutual information
#### Rlative Entropy / KL divergence
#### Properties of KL divergence
#### Convex Function
#### Chord
#### Strictly Convex
#### Concave
#### Jensen's Inequality
#### Relationship to Data Compression
#### Minimizing KL Divergence
#### Mutual Information
#### Relation of MI to Conditional Entropy
#### Bayesian Perspective
